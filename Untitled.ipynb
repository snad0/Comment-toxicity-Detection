{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "849ed98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\python310\\lib\\site-packages (2.8.0rc1)\n",
      "Requirement already satisfied: pandas in c:\\python310\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: matplotlib in c:\\python310\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: sklearn in c:\\python310\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\python310\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\python310\\lib\\site-packages (from tensorflow) (1.13.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\python310\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\python310\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\python310\\lib\\site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\python310\\lib\\site-packages (from tensorflow) (0.23.1)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\python310\\lib\\site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\python310\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\python310\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\python310\\lib\\site-packages (from tensorflow) (4.0.1)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in c:\\python310\\lib\\site-packages (from tensorflow) (2.8.0rc1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (1.22.3)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\python310\\lib\\site-packages (from tensorflow) (3.19.4)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\python310\\lib\\site-packages (from tensorflow) (1.43.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\python310\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\python310\\lib\\site-packages (from tensorflow) (13.0.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (62.3.1)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in c:\\python310\\lib\\site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in c:\\python310\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in c:\\python310\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in c:\\python310\\lib\\site-packages (from tensorflow) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\python310\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python310\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\python310\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\python310\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\python310\\lib\\site-packages (from matplotlib) (3.0.6)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\python310\\lib\\site-packages (from matplotlib) (9.0.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\python310\\lib\\site-packages (from matplotlib) (4.28.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python310\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\python310\\lib\\site-packages (from sklearn) (1.0.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\python310\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\python310\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\python310\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\python310\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\python310\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\python310\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\python310\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\python310\\lib\\site-packages (from scikit-learn->sklearn) (1.7.3)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\python310\\lib\\site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\python310\\lib\\site-packages (from scikit-learn->sklearn) (3.0.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\python310\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.8)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\python310\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow pandas matplotlib sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2952bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c42f2fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= pd.read_csv(\"train.csv/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9b35dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee39db84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[6][\"comment_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "421334fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic            1\n",
       "severe_toxic     1\n",
       "obscene          1\n",
       "threat           0\n",
       "insult           1\n",
       "identity_hate    0\n",
       "Name: 6, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[dataset.columns[2:]].iloc[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6393ef89",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b72e797a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first we need to convert text comments into vectors so that we can apply a deep network on it\n",
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0f0819e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n",
       "       'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21c55203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "0           0             0        0       0       0              0\n",
       "1           0             0        0       0       0              0\n",
       "2           0             0        0       0       0              0\n",
       "3           0             0        0       0       0              0\n",
       "4           0             0        0       0       0              0\n",
       "...       ...           ...      ...     ...     ...            ...\n",
       "159566      0             0        0       0       0              0\n",
       "159567      0             0        0       0       0              0\n",
       "159568      0             0        0       0       0              0\n",
       "159569      0             0        0       0       0              0\n",
       "159570      0             0        0       0       0              0\n",
       "\n",
       "[159571 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[dataset.columns[2:]] #now i can convert it into a numpy array using .values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a03d8bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dataset[\"comment_text\"]\n",
    "Y=dataset[dataset.columns[2:]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5926e98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8cdf92a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Explanation\\nWhy the edits made under my usern...\n",
       "1         D'aww! He matches this background colour I'm s...\n",
       "2         Hey man, I'm really not trying to edit war. It...\n",
       "3         \"\\nMore\\nI can't make any real suggestions on ...\n",
       "4         You, sir, are my hero. Any chance you remember...\n",
       "                                ...                        \n",
       "159566    \":::::And for the second time of asking, when ...\n",
       "159567    You should be ashamed of yourself \\n\\nThat is ...\n",
       "159568    Spitzer \\n\\nUmm, theres no actual article for ...\n",
       "159569    And it looks like it was actually you who put ...\n",
       "159570    \"\\nAnd ... I really don't think you understand...\n",
       "Name: comment_text, Length: 159571, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b061710b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize=TextVectorization(max_tokens=200000,output_sequence_length=1800,\n",
    "                           output_mode=\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42975906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\",\n",
       "       \"D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)\",\n",
       "       \"Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.\",\n",
       "       ...,\n",
       "       'Spitzer \\n\\nUmm, theres no actual article for prostitution ring.  - Crunch Captain.',\n",
       "       'And it looks like it was actually you who put on the speedy to have the first version deleted now that I look at it.',\n",
       "       '\"\\nAnd ... I really don\\'t think you understand.  I came here and my idea was bad right away.  What kind of community goes \"\"you have bad ideas\"\" go away, instead of helping rewrite them.   \"'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.values #-------> into a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1eee25fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize.adapt(X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e8706c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int64, numpy=array([87302,   261], dtype=int64)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize(\"Hellow World\")[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e389ac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_text=vectorize(X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4309896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(159571, 1800), dtype=int64, numpy=\n",
       "array([[  643,    76,     2, ...,     0,     0,     0],\n",
       "       [    1,    54,  2506, ...,     0,     0,     0],\n",
       "       [  425,   440,    70, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [32141,  7329,   383, ...,     0,     0,     0],\n",
       "       [    5,    12,   533, ...,     0,     0,     0],\n",
       "       [    5,     8,   130, ...,     0,     0,     0]], dtype=int64)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "04ef4066",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.data.Dataset.from_tensor_slices((vectorized_text,Y))\n",
    "data=data.cache()\n",
    "data=data.shuffle(160000)\n",
    "data=data.batch(16)\n",
    "data=data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b4350f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[    2,  6432,   307, ...,     0,     0,     0],\n",
       "        [    8,   210,     9, ...,     0,     0,     0],\n",
       "        [   76,    92,    15, ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  918,   918,  3211, ...,     0,     0,     0],\n",
       "        [58268,   236, 19499, ...,     0,     0,     0],\n",
       "        [14899,   191,   925, ...,     0,     0,     0]], dtype=int64),\n",
       " array([[0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0]], dtype=int64))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0dece6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X, batch_Y = data.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7dea3013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 1800)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "efa614c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Partition the dataset\n",
    "train = data.take(int(len(data)*.7))\n",
    "val=  data.skip(int(len(data)*.7)).take(int(len(data)*.2))\n",
    "test = data.skip(int(len(data)*.9)).take(int(len(data)*.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6f499e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator= train.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "27adb022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  6345,   2205,     20, ...,      0,      0,      0],\n",
       "        [   727,     40,    574, ...,      0,      0,      0],\n",
       "        [ 34281,    466,    489, ...,      0,      0,      0],\n",
       "        ...,\n",
       "        [106831,     25,   1564, ...,      0,      0,      0],\n",
       "        [    30,    562,     31, ...,      0,      0,      0],\n",
       "        [   165,     30,   1183, ...,      0,      0,      0]], dtype=int64),\n",
       " array([[0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 0, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 1, 0]], dtype=int64))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5ca968",
   "metadata": {},
   "source": [
    "# Creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6e0946b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Bidirectional, Dense, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b18de101",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Sequential()\n",
    "# model.add(Embedded(Max_Number of words+1,32))\n",
    "model.add(Embedding(200000+1,32))\n",
    "\n",
    "model.add(Bidirectional (LSTM(32,activation='tanh')))\n",
    "\n",
    "\n",
    "model.add(Dense(128, activation ='relu'))\n",
    "model.add(Dense(256, activation ='relu'))\n",
    "model.add(Dense(128, activation ='relu'))\n",
    "\n",
    "#final layer for classification\n",
    "model.add(Dense(6, activation ='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "28cb859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='BinaryCrossentropy', optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "62a284e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 32)          6400032   \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 64)               16640     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,491,686\n",
      "Trainable params: 6,491,686\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1e689a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history= model.fit(train, epochs=10, validation_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb1f7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model=tf.keras.models.load_model(\"toxicity.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1b0fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e954b556",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "pd.DataFrame(history.history).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28520c0",
   "metadata": {},
   "source": [
    "# Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbc4b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch= test.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bf7cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text=vectorize(\"Hi stupid bro i will kill you murder you tonight i am comming to fuck you\")\n",
    "\n",
    "res= model.predict(np.expand_dims(input_text, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d371887",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d028b955",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch= test.as_numpy_iterator().next()\n",
    "test_batch_X, test_batch_Y = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194e5761",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(test_batch_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e723211",
   "metadata": {},
   "outputs": [],
   "source": [
    "(model.predict(test_batch_X) >0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cedc1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs= model.predict(batch_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a61bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77141fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4c5fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre= Precision()\n",
    "re = Recall()\n",
    "acc= CategoricalAccuracy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3df764",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre= Precision()\n",
    "re = Recall()\n",
    "acc= CategoricalAccuracy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb33022",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Precissiion: {pre.result().numpy()}, Recall: {re.result().numpy()}, Accuracy: {acc.result().numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f3e593",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68b88ea6",
   "metadata": {},
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43565428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "paths = {\n",
    "    'CHECKPOINT_PATH': os.path.join('Tensorflow'),\n",
    " }\n",
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {path}\n",
    "        if os.name == 'nt':\n",
    "            !mkdir {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40ee8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "model_version=max([int(i) for i in os.listdir(\"Tensorflow\") + [0]])+1\n",
    "model.save(f\"Tensorflow/{model_version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7b4f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"toxicity.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adb0eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lOADING SAVED MODEL\n",
    "import tensorflow as tf\n",
    "model=tf.keras.models.load_model(\"toxicity.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f69eb7",
   "metadata": {},
   "source": [
    "# For Gradio App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dadd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gradio jinja2\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b3e39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_comment(comment):\n",
    "  vectorized_comment=vectorize([comment])\n",
    "  results= model.predict(vectorized_comment)\n",
    "\n",
    "  text=''\n",
    "  for idx, col in enumerate(dataset.columns[2:]):\n",
    "    text += '{}: {}\\n'.format(col, results[0][idx]>0.5)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b4043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "interface=gr.Interface(fn=score_comment, inputs=gr.inputs.Textbox(lines=2,placeholder='Commebnt to check'),\n",
    "                       outputs='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d31989",
   "metadata": {},
   "outputs": [],
   "source": [
    "interface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
